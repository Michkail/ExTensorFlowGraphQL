{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexpress\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpx\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_objects\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mgo\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mplotly\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msubplots\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m make_subplots\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "supply_data = pd.read_csv(\"supply_chain_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T11:15:41.568006Z",
     "start_time": "2024-05-06T11:15:41.547493Z"
    }
   },
   "id": "fb3e036a5c18a695",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'supply_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43msupply_data\u001B[49m\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[1;31mNameError\u001B[0m: name 'supply_data' is not defined"
     ]
    }
   ],
   "source": [
    "supply_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T10:58:58.953511Z",
     "start_time": "2024-05-06T10:58:58.907176Z"
    }
   },
   "id": "f955b610736b5025",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supply_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "supply_data.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea1e5fa74b77f6f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "supply_data.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "628a5419349261f8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "missing_values = supply_data.isnull().sum()\n",
    "\n",
    "# Display columns with missing values and the count of missing values\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "\n",
    "if not missing_values.empty:\n",
    "    print(\"Columns with missing values:\")\n",
    "    \n",
    "    for column, count in missing_values.items():\n",
    "        print(f\"{column}: {count} missing values\")\n",
    "        \n",
    "else:\n",
    "    print(\"There are no columns with missing value\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4f0b8117738df6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check for duplicate data\n",
    "\n",
    "if supply_data.duplicated().any():\n",
    "    print(f\"There are as many as {supply_data.duplicated().sum()} duplicate data.\")\n",
    "    \n",
    "else:\n",
    "    print(\"There are no duplicate data.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc1d7cd1fb62c363"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Quality control check\n",
    "\n",
    "defect_rates_by_product = supply_data.groupby(\"Product type\")['Defect rates'].mean().reset_index()\n",
    "\n",
    "# Create a bar chart using Plotly\n",
    "fig = px.bar(defect_rates_by_product, x='Product type', y='Defect rates', title='Defect Rates by Product Type')\n",
    "\n",
    "# Customize the color scale for bars\n",
    "color_scale = px.colors.qualitative.Set3  # You can choose a different color scale\n",
    "fig.update_traces(marker_color=color_scale)\n",
    "\n",
    "# Customize the appearance of the chart\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Product Type\",\n",
    "    yaxis_title=\"Mean Defect Rates\",\n",
    "    xaxis=dict(categoryorder='total descending'),\n",
    "    yaxis=dict(title='Mean Defect Rates'),\n",
    "    plot_bgcolor='white',\n",
    "    title_x=0.5,\n",
    "    showlegend=True  # Hide the legend\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78f5ac06fc5598ab"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Supply chain risk management\n",
    "\n",
    "risk_data = supply_data[['SKU', 'Lead times', 'Stock levels']]\n",
    "risk_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a0cd0911b4fff9d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "risk_data['Risk score'] = risk_data['Lead times'] * (1-risk_data.loc[:,'Stock levels'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b73399cf70852a9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Sort the risk_data by 'Risk score' in descending order and select top 10 highest-risk data\n",
    "risk_data = risk_data.sort_values(by='Risk score', ascending=False)[:10]\n",
    "\n",
    "# Create a bar plot using Plotly Express\n",
    "fig = px.bar(risk_data, x='SKU', y='Risk score', title='Top 10 Highest-Risk Data',\n",
    "             labels={'Risk score': 'Risk Score', 'SKU': 'SKU'},\n",
    "             text='Risk score')\n",
    "\n",
    "# Customize the appearance of the plot\n",
    "fig.update_traces(texttemplate='%{text:.2f}', textposition='outside')\n",
    "fig.update_layout(xaxis_title='SKU', yaxis_title='Risk Score', title_x=0.5)\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df3d5ec56b3c4574"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# we assume for holding cost 0.2\n",
    "holdingcost = 0.2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T08:49:47.416601Z",
     "start_time": "2024-05-06T08:49:47.407308Z"
    }
   },
   "id": "da8830c1e56d614f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_eoq(data):\n",
    "    S = data['Costs']\n",
    "    D = data['Number of products sold'] \n",
    "    H = data['Number of products sold'] * holdingcost\n",
    "    EOQ = np.sqrt((2*S*D)/H)\n",
    "    return round(EOQ)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a72fc96cddcb8e47"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "supply_data['EOQ'] = calculate_eoq(supply_data)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c88438efb62592b3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "comparison_columns = supply_data[['SKU', 'EOQ','Order quantities']]\n",
    "comparison_columns.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42b635a4b74d315f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Extracting the top 10 rows for comparison\n",
    "top_10_comparison = comparison_columns.head(10)\n",
    "\n",
    "# Creating a bar plot to compare EOQ and Order Quantities for the top 10 SKUs\n",
    "fig = px.bar(top_10_comparison, x='SKU', y=['EOQ', 'Order quantities'], \n",
    "             title='Comparison of EOQ and Order Quantities for Top 10 SKUs')\n",
    "\n",
    "fig.update_layout(\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "# Displaying the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db3795e6ad33226"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Customer segmentation analysis\n",
    "\n",
    "revenue_avg_by_demo_prod = supply_data.groupby(['Customer demographics', 'Product type'])['Revenue generated'].mean().reset_index()\n",
    "revenue_sum_by_demo_prod = supply_data.groupby(['Customer demographics', 'Product type'])['Revenue generated'].sum().reset_index()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c80bc106d78a812"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a palette of different colors for each product type\n",
    "colors = px.colors.qualitative.Set3\n",
    "\n",
    "# Create a subplot with 1 row and 2 columns\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=('Average Revenue', 'Total Revenue'))\n",
    "\n",
    "# Plot for average revenue\n",
    "for i, product_type in enumerate(revenue_avg_by_demo_prod['Product type'].unique()):\n",
    "    subset = revenue_avg_by_demo_prod[revenue_avg_by_demo_prod['Product type'] == product_type]\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=subset['Customer demographics'],\n",
    "            y=subset['Revenue generated'],\n",
    "            name=product_type,\n",
    "            marker_color=colors[i]\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot for total revenue without legend\n",
    "for i, product_type in enumerate(revenue_sum_by_demo_prod['Product type'].unique()):\n",
    "    subset = revenue_sum_by_demo_prod[revenue_sum_by_demo_prod['Product type'] == product_type]\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=subset['Customer demographics'],\n",
    "            y=subset['Revenue generated'],\n",
    "            showlegend=False,  # Hide legend for this subplot\n",
    "            marker_color=colors[i]\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Beautify the subplot and show the legend for the first subplot\n",
    "fig.update_layout(\n",
    "    title='Revenue Analysis by Customer Demographics and Product Type',\n",
    "    xaxis=dict(title='Customer Demographics'),\n",
    "    yaxis=dict(title='Revenue'),\n",
    "    xaxis2=dict(title='Customer Demographics'),\n",
    "    yaxis2=dict(title='Revenue'),\n",
    "    title_x=0.5,\n",
    "    showlegend=True  # Show legend for the first subplot\n",
    ")\n",
    "\n",
    "# Show the subplot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a844bcb90456e20e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Lead times optimization analysis\n",
    "\n",
    "avg_lead_times_transport = supply_data.groupby(['Transportation modes'])['Lead times'].mean().reset_index()\n",
    "\n",
    "fig = px.bar(avg_lead_times_transport, x='Transportation modes', y='Lead times',\n",
    "             labels={'Transportation modes': 'Transportation Mode', 'Lead times': 'Average Lead Time'},\n",
    "             title='Average Lead Times by Transportation Mode')\n",
    "\n",
    "# Customize the color scale for bars\n",
    "color_scale = px.colors.qualitative.Set3  # You can choose a different color scale\n",
    "fig.update_traces(marker_color=color_scale)\n",
    "\n",
    "# Customize the layout for beautification\n",
    "fig.update_layout(\n",
    "    title=dict(text='Average Lead Times by Transportation Mode', x=0.5),\n",
    "    xaxis_title='Transportation Mode',\n",
    "    yaxis_title='Average Lead Time',\n",
    "    xaxis_tickangle=-45,  # Rotate x-axis labels for better readability\n",
    "    font=dict(family=\"Arial\", size=14),\n",
    "    showlegend=False  # Remove legend\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "81c71367b868346e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_transportation_mode = avg_lead_times_transport.loc[avg_lead_times_transport['Lead times'].idxmin()]\n",
    "best_transportation_mode"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69af09c466c64167"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_transportation_data = supply_data[supply_data['Transportation modes']==best_transportation_mode['Transportation modes']]\n",
    "best_transportation_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "780f3932fea97ef7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "avg_lead_times_route = supply_data.groupby(['Routes'])['Lead times'].mean().reset_index()\n",
    "\n",
    "# Assuming you have the avg_lead_times_route DataFrame already defined\n",
    "fig = px.bar(avg_lead_times_route, x='Routes', y='Lead times',\n",
    "             labels={'Routes': 'Route', 'Lead times': 'Average Lead Time'},\n",
    "             title='Average Lead Times by Route')\n",
    "\n",
    "# Customize the color scale for bars\n",
    "color_scale = px.colors.qualitative.Set3  # You can choose a different color scale\n",
    "fig.update_traces(marker_color=color_scale)\n",
    "\n",
    "# Customize the layout for beautification\n",
    "fig.update_layout(\n",
    "    title=dict(text='Average Lead Times by Route', x=0.5),\n",
    "    xaxis_title='Route',\n",
    "    yaxis_title='Average Lead Time',\n",
    "    xaxis_tickangle=-45,  # Rotate x-axis labels for better readability\n",
    "    font=dict(family=\"Arial\", size=14),\n",
    "    showlegend=False  # Remove legend\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ffed185427a7dd8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_route = avg_lead_times_route.loc[avg_lead_times_route['Lead times'].idxmin()]\n",
    "best_route"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faf99ea8b77720c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "best_route_data = supply_data[supply_data['Routes']==best_route['Routes']]\n",
    "best_route_data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71e9a8e4723cd380"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Modelling\n",
    "\n",
    "# Forecasting demand\n",
    "X = supply_data.loc[:,['Price', 'Availability', 'Stock levels', 'Lead times', 'Order quantities']]\n",
    "y = supply_data.loc[:,'Number of products sold']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f57ce2d6fc37c869"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "num_folds = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abc1a7785ba85288"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8c9e8da18b9337c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66575a5e03306bf1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mean_squared_error',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5c367d11c823509"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Create LightGBM datasets for training and testing\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "    \n",
    "    # Add early stopping\n",
    "    num_round = 100  # Increase the number of boosting rounds\n",
    "    early_stopping_rounds = 5  # Set the number of rounds to wait for early stopping\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        train_data,\n",
    "        num_round,\n",
    "        valid_sets=[test_data],\n",
    "        early_stopping_rounds=early_stopping_rounds,\n",
    "        verbose_eval=10\n",
    "    )\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate the target range\n",
    "    target_range = np.max(y_test) - np.min(y_test)\n",
    "\n",
    "    # Calculate metrics as percentages\n",
    "    percentage_mse = (mse / target_range) * 100\n",
    "    percentage_rmse = (rmse / target_range) * 100\n",
    "    percentage_mae = (mae / target_range) * 100\n",
    "    percentage_r2 = (r2 * 100)\n",
    "\n",
    "    # Append the scores to the respective lists\n",
    "    mse_scores.append(percentage_mse)\n",
    "    rmse_scores.append(percentage_rmse)\n",
    "    mae_scores.append(percentage_mae)\n",
    "    r2_scores.append(percentage_r2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17d6d942f4415abc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the average scores over all folds\n",
    "avg_mse = np.mean(mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_r2 = np.mean(r2_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Mean Squared Error: {avg_mse:.2f}%\")\n",
    "print(f\"Average Root Mean Squared Error: {avg_rmse:.2f}%\")\n",
    "print(f\"Average Mean Absolute Error: {avg_mae:.2f}%\")\n",
    "print(f\"Average R-squared: {avg_r2:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30e4ae0d74f63359"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Cost optimization\n",
    "\n",
    "# Extract the features (X) and target (y)\n",
    "X = supply_data.loc[:, 'Production volumes'].values.reshape(-1, 1)\n",
    "y = supply_data.loc[:, 'Manufacturing costs'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T09:15:17.435634Z",
     "start_time": "2024-05-06T09:15:17.431121Z"
    }
   },
   "id": "1db8479cec0a9bd5",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a971a7d7b769c9c4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize lists to store evaluation metrics\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "mae_scores = []\n",
    "r2_scores = []"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e296b05ede18ea79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Initialize and fit the scaler to the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6949be4050e1e3ae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a KFold object\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a7bf8ba5bac4347"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Scale the data\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Define and compile the neural network model\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(64, activation='relu', input_dim=1),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Define Early Stopping callback\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Define Model Checkpoint callback to save the best model\n",
    "    model_checkpoint = ModelCheckpoint('/kaggle/working/best_model.h5', save_best_only=True, save_weights_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # Train the model on the training data with callbacks\n",
    "    history = model.fit(X_train_scaled,\n",
    "                        y_train, epochs=100,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_test_scaled, y_test),\n",
    "                        callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "    # Load the best model weights from the saved checkpoint\n",
    "    model.load_weights('/kaggle/working/best_model.h5')\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(y_test - y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate metrics as percentages\n",
    "    target_range = np.max(y_test) - np.min(y_test)\n",
    "    percentage_mse = (mse / target_range) * 100\n",
    "    percentage_rmse = (rmse / target_range) * 100\n",
    "    percentage_mae = (mae / target_range) * 100\n",
    "    percentage_r2 = (r2 * 100)\n",
    "\n",
    "    # Append the scores to the respective lists\n",
    "    mse_scores.append(percentage_mse)\n",
    "    rmse_scores.append(percentage_rmse)\n",
    "    mae_scores.append(percentage_mae)\n",
    "    r2_scores.append(percentage_r2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1fd7bdeca2a4db87"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Calculate the average scores over all folds\n",
    "avg_mse = np.mean(mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_mae = np.mean(mae_scores)\n",
    "avg_r2 = np.mean(r2_scores)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Average Mean Squared Error: {avg_mse:.2f}%\")\n",
    "print(f\"Average Root Mean Squared Error: {avg_rmse:.2f}%\")\n",
    "print(f\"Average Mean Absolute Error: {avg_mae:.2f}%\")\n",
    "print(f\"Average R-squared: {avg_r2:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ea28e42228a33f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Find the most optimal production volume to minimize manufacturing cost\n",
    "min_production_volume = supply_data['Production volumes'].min()\n",
    "max_production_volume = 1000\n",
    "step_size = 100\n",
    "\n",
    "cheapest_cost = float('inf')\n",
    "best_production_volume = None\n",
    "\n",
    "for production_volume in range(min_production_volume, max_production_volume + 1, step_size):\n",
    "    normalized_production_volume = scaler.transform(np.array([[production_volume]]))\n",
    "    predicted_cost = model.predict(normalized_production_volume)\n",
    "\n",
    "    if predicted_cost[0][0] < cheapest_cost:\n",
    "        cheapest_cost = predicted_cost[0][0]\n",
    "        best_production_volume = production_volume\n",
    "\n",
    "print('Most optimal production volume to minimize manufacturing cost:', best_production_volume)\n",
    "print('The cheapest manufacturing cost:', cheapest_cost)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea1b1b2e220f7046"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
